# Copyright 2020 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# [START workflows_connector_bigquery]
# This workflow demonstrates how to use the BigQuery connector.
# The workflow creates a new dataset and then issues a simple query to insert a table with
# some data from bigquery-public-data.usa_names.usa_1910_2013.
# The new table and dataset are both deleted in the following steps.
# Expected successful output: "SUCCESS"

- init:
    assign:
    - project_id: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
    - dataset_id: "dummy_dataset"
    - table_id: "dummy_table"
    - query: "SELECT * FROM `bigquery-public-data.usa_names.usa_1910_2013` LIMIT 5000;"
    - create_disposition: "CREATE_IF_NEEDED"  # create a new one if table doesn't exist
    - write_disposition: "WRITE_TRUNCATE"  # truncate it if the table already exists
- create_dataset:
    call: googleapis.bigquery.v2.datasets.insert
    args:
      projectId: ${project_id}
      body:
        datasetReference:
          datasetId: ${dataset_id}
          projectId: ${project_id}
        access[].role: "roles/bigquery.dataViewer"
        access[].specialGroup: "projectReaders"
- insert_table_into_dataset:
    call: googleapis.bigquery.v2.jobs.insert
    args:
      projectId: ${project_id}
      body:
        configuration:
          query:
            query: ${query}
            destinationTable:
              projectId: ${project_id}
              datasetId: ${dataset_id}
              tableId: ${table_id}
            create_disposition: ${create_disposition}
            write_disposition: ${write_disposition}
            allowLargeResults: true
            useLegacySql: false
- delete_table_from_dataset:
    call: googleapis.bigquery.v2.tables.delete
    args:
      projectId: ${project_id}
      datasetId: ${dataset_id}
      tableId: ${table_id}
- delete_dataset:
    call: googleapis.bigquery.v2.datasets.delete
    args:
      projectId: ${project_id}
      datasetId: ${dataset_id}
- the_end:
    return: "SUCCESS"
# [END workflows_connector_bigquery]
